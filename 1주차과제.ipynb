{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차과제.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTZrpmdzRfwAK0BTFpNfSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banghanbyeol/AI_assignment/blob/master/1%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19xWympzCq4t",
        "colab_type": "text"
      },
      "source": [
        "## 언어\n",
        "신경망 기계번역(NMT)을 도입한 언어 번역기과 API가 많아졌다.\n",
        "신경망 기계번역(NMT, Neural Machine Translation)은 사람의 뇌가 사고하는 과정과 비슷하게 번역하는 기술이다. 통계 기반 번역(SMT, Statistical Machine Translation)과 비교했을 때 번역의 단위와 방식에서 차이를 보인다. SMT는 문장을 단어나 구로 쪼개어 번역하고, 확률적으로 유사한 단어로 교체하는 것과는 다르게 NMT는 문장을 통째로 번역한다.\n",
        "\n",
        "[SMT번역]\n",
        "God will save us -> 신이 우리를 저장할 것이다.\n",
        "\n",
        "[NMT번역]\n",
        "God will save us -> 신이 우리를 구원할 것이다.\n",
        "\n",
        "원문과 해석문을 입력한 후 컴퓨터가 원문과 해석문을 쌍으로 비교하여, 해석문에 도달하는 최적의 가중치를 스스로 학습하도록 한다. 초기의 학습은 개발자가 계속적으로 감시하지만, 이후에는 컴퓨터 스스로 머신러닝을 수행하게 된다. 이러한 반복을 거쳐 '컴퓨터 스스로 최적의 가중치를 두고, 번역 대상과 번역 결과 상호를 비교하면서 최적의 데이터를 도출하는 모델' 을 만든다. 인공지능 모델은 어순, 문장 속에서의 의미까지 반영하여 번역 결과물을 내놓는다.\n",
        "\n",
        "NMT가 각광받는 이유는 기존 모델에 비해 간단하면서도 좋은 성능을 내주기 때문인데 단점 또한 존재한다.\n",
        "1. 느린 학습(training)속도와 느린 추론(interference)속도\n",
        "- 데이터가 크기 때문에 속도가 느리고 모델 파라미터가 많아 단위 연산 비용이 높기 때문에 추론속도 또한 느리다.\n",
        "2. 드물게 등장하는 단어에 대한 부정확도\n",
        "- 아주 드물게 등장하는 단어는 추론시 사전에 없을 수 있다. \n",
        "3. 가끔씩 전체 입력 문장에 대해 모든 번역을 하지 않는 경우가 있다.\n",
        "\n",
        "구글은 구글 신경망 기계번역 기술인 GNMT(Google Neural Machine Translation)을 적용한 번역기를 선보였다. NMT의 문제점을 해결하고 학습시 속도를 올리기 위해 low-precision연산을 처리한다. 드물게 등장하는 단어의 처리를 위해 wordpiece를 사용했으며 GPU문제 또한 CPU/TPU에서 번역 서비스를 가능하게 했다.\n",
        "\n",
        "## 음성\n",
        "과거 음성합성은 사용 빈도가 높은 문장을 녹음하고 음소 단위로 분리해 텍스트로 재결합하는 방법인 '연결합성(Concatenative synthesis)', USS(Unit Selection Synthesis)'을 사용해왔다. 음소 단위의 유닛으로 분리된 음성의 데이터베이스를 구축한 후 텍스트가 입력되면 적절한 유닛을 선택해 순서대로 합성하는 방식이다. 원음을 분리한 뒤 합성하는 방식은 원음을 그대로 표현할 수 있지만 많은 유닛을 필요로 한다. 또한 복잡한 과정에서도 특정 유닛이 필요한데, 데이터베이스에 맞는 유닛이 없을 경우도 문제가 된다.\n",
        "\n",
        "통계기반 파라미터 음성합성(Statistical parametric speech synthesis)기술은 연결합성의 단점을 보완한 방식이다. 음성의 특징을 모델링하여 훈련된 모델로부터 파라미터를 생성해 목소리를 만들어내는 형식이기 때문에 연결합성에 비해 더 적은 데이터로 개발할 수 있다. 용량이 작아 모바일 기기에서도 효율적이나 변환하는 단계에서 일부 손실이 발생하여 부자연스럽고 음질이 다소 낮다.\n",
        "\n",
        "기존의 음성합성 기술의 단점을 극복하기 위한 인공지능(AI)기술이 떠오르고 있다. 음성의 파라미터를 통계 기반으로 예측하던 것에서 AI로 예측해 운율과 음질이 개선되었지만 입력 텍스트의 문맥 정보를 분석하는 한계 때문에 여전히 낮은 음질이라는 단점이 존재했다. 구글의 타코트론(Tacotron) 기반 음성합성기의 등장으로 텍스트나 음원의 전처리 과정 없이 입력 텍스트로부터 바로 음성을 예측할 수 있게 되었다. 텍스트와 음원 사이의 연관성을 AI가 스스로 학습하기 때문에 실제 사람이 말하는 것과 같은 자연스러운 합성 품질을 보이며, 개발 장벽도 낮아졌다.\n",
        "\n",
        "AI 음성합성기는 적은 데이터로 빠르게 사람같은 음성을 만들어낼 수 있다. 음성을 유닛으로 분리하거나 통계적으로 모델링 하지 않고, 데이터의 양상을 학습하기 때문에 목소리 선택 폭이 넓다. AI 음성합성기가 등장하면서 훨씬 낮은 비용, 더 빠른 시간 내에 음성 콘텐츠를 개발 할 수 있다.\n",
        "\n",
        "이러한 AI 음성합성기에는 전이학습(Transfer learning)이 활용된다. 전이학습은 잘 훈련된 'Pre trained model'을 응용해 데이터를 새롭게 학습하는 방식이다. 모델을 두 개 사용하여 특적 목적을 가진 학습된 모델을 다른 일의 시작 포인트에서 재사용하는 머신러닝의 방법이다. 딥러닝 기반의 음성합성 기술은 전문 성우가 아닌 원하는 누군가의 목소리로 짧은 시간 안에 음성합성기를 만들 수 있어 '커스텀보이스'가 가능하다.\n",
        "\n",
        "AI 음성합성기도 극복해야 할 과제가 있다. 타코트론의 경우 모든 과정이 예측 기반으로 이뤄지기 때문에 예측 성능에 따른 문제들이 발생한다. 음을 반복하거나 생략, 잘못 발성하는 문제가 있다. 문장이 길 수록 문장 생성이 오래 걸리기 때문에 실시간 서비스를 요구하는 챗봇이나 인공지능 스피커에서 적합하지 않다. 엔드 투 엔드(End to End) 음성합성을 사용하지만 음성의 스펙트로그램을 생성하고 음성파형으로 변환하는 과정에서 손실이 발생하기 때문에 음질이 좋지 않다.\n",
        "\n",
        "이를 극복하기 위해 'Neural vocoder'는 단순 연산이 아닌 신경망을 통해 스펙트로그램을 음성파형으로 변환하는 것으로 원음에 가깝게 출력할 수 있으나 연산에 GPU가 요구되는 제약 사항이 따른다. AI 음성합성기가 산업 현장에 적용되려면 자연스러운 음성과 합성음을 안정적으로 생성할 수 있어야 하며, 빠른 시간 안에 사용자에게 응답하면서 고품질을 유지할 수 있어야 한다.\n",
        "\n",
        "## 이미지\n",
        "사진을 '음식', '동물' 등으로 자동 분류해 주는 구글 포토, 카메라를 비추면 어떤 사물인지 알려주는 구글 렌즈 등의 AI 이미지 분석 기술의 사례가 있다.\n",
        "'노이즈(Noise)'를 얼마나 판별해 내는지가 AI 이미지 분석의 핵심 기술이다. AI는 각각의 데이터(픽셀)로 이미지를 분석하기 때문에 노이즈는 아니지만 객체의 구도와 모양, 색이 유사하여 이미지 분석을 혼란스럽게 만드는 경우도 있다. 모양이나 질감이 유사한 경우 잘못 인식하는 문제가 발생한다. AI 이미지 인식에서 가장 중요한 요소는 판별하고자 하는 이미지의 특징(feature)을 포착하고 추상화해야 한다.\n",
        "\n",
        "CNN(Convolutional Neural Network)은 이미지 인식에 좋은 성능을 보이고 가장 널리 사용되는 알고리즘이다. 기존의 FCNN(Fully Connected Neural Network)는 첫 레이어에서 특징을 잡아냈어도, 다음 레이어로 넘어가면서 전체가 섞여 특징이 희석된다. CNN의 경우 이미지의 특징별로 뉴런 그룹을 만들어 일부만 연결하기 때문에 다음 레이어로 넘어가도 특징이 유지된다. 필터를 공유파라미터로 사용하기 때문에 학습할 파라미터(가중치와 편향)가 적어진다. 모든 픽셀을 분석적으로 하지않고 지역적, 공간적 상관관계를 고려한 학습을 하기 때문에 효율적으로 분류 작업에 높은 성능을 보인다.\n",
        "사람의 시각 피질 메커니즘에 영감을 받아 설계된 네트워크이다. 지역적 연결(local connection)과 파라미터 공유(shared weight)를 고려하여 학습한다.\n",
        "\n",
        "CNN은 다른 신경망과 마찬가지로 입력 계층, 출력 계층 및 두 계층 사이의 여러 은닉 계층으로 구성된다. 각 계층은 해당 데이터만이 갖는 특징을 학습하기 위해 데이터를 변경하는 계산을 수행한다. 가장 자주 사용되는 계층으로는 컨벌루션, 활성화/ReLU, 풀링이 있다. 이러한 작업이 수십 개 또는 수백 개의 계층에서 반복되어 각 계층이 여러 특징을 검출하는 방법을 학습하게 된다.\n",
        "\n",
        "## 자율주행\n",
        "자율주행 자동차가 스스로 주행하려면 주변 환경인지 주행 도로를 판단하고 선정해야 하며 안전한 기능 제어 등의 기능이 반드시 수반돼야 한다.\n",
        "\n",
        "인지 기능은 카메라, 레이더, 라이다(LiDAR) 등 차체 내 센서 정보를 처리해 주변 환경 정보를 알아차리는 것이다. 판단 기능은 인지된 정보를 이용해 향후 벌어질 일을 예측하여 가장 안전하고 빠른 차량 궤적을 생성해야 한다. 제어 기능은 최종적으로 생성된 차량 궤적을 부드럽고 정확하게 따라갈 수 있도록 운전대, 액셀러레이터, 브레이크를 조작하는 것이다.\n",
        "\n",
        "특히 카메라를 통해 입력된 이미지에 딥러닝을 적용하면 자율주행 시스템에 필요한 정적 환경 정보(차선, 운전가능도로, 교통표지판, 교통신호 등) 과 동적 환경 요소(차량, 보행자, 이륜차 등)를 전부 검출하고 분류할 수 있다.\n",
        "\n",
        "딥러닝은 차량의 궤적을 생성하는 판단 기능에도 사용될 수 있다. 미래의 움직임을 판단하고 결정하려면 다른 운전자의 움직임을 예측해야 되는데 다양한 운전 방식을 파악하고 수학 모델로 정의되기는 쉽지 않다. 다른 차량 운전자가 어떻게 운전할지 논리적으로 예측하는 건 불가능하다. 그러나 다양한 운전 방식과 관련 센서 정보를 데이터로 입력한 후 이를 딥러닝 알고리즘으로 학습하면 정확한 수학 모델 없이 데이터만으로 다른 운전자의 운행을 예측할 수 있는 인공지능 구현이 가능하다.\n",
        "\n",
        "엔드 투 엔드(End-to-End) 자율주행은 운전의 전 과정을 통째로 학습하는 딥러닝 방식이다. 이 방식을 자율주행 자동차에 적용하면 새로운 운행 환경에 대한 추가 기능이 필요할 때마다 인지, 판단, 제어 알고리즘을 다시 설계하거나 변경하지 않고, 새로운 상황에 대한 데이터를 추가적으로 학습하여 자율주행 시스템을 구현할 수 있다. 운전에 필요한 센서 데이터를 직접 입력 받고 다양한 운행 상황에 대해 학습한 후 스티어링(steering)과 엑셀러레이터, 브레이크 값을 직접 출력해낸다. 운전자의 운행 방식을 데이터로 수집하고 이를 모방하는 학습 방식과 시뮬레이터를 이용해 가장 최적화된 운전 방식을 스스로 학습하는 강화학습을 기반으로 하고 있다. \n",
        "## 출처\n",
        "\n",
        "- 언어\n",
        "- https://blog.naver.com/skaibril/221404594341\n",
        "- https://www.ibm.com/kr-ko/cloud/watson-language-translator\n",
        "- https://www.slideshare.net/ByeongilKo/gnmt-69817390\n",
        "- https://norman3.github.io/papers/docs/google_neural_machine_translation.html\n",
        "-음성\n",
        "- http://www.epnc.co.kr/news/articleView.html?idxno=95069\n",
        "- http://www.epnc.co.kr/news/articleView.html?idxno=93221\n",
        "-이미지\n",
        "- https://wonwooddo.tistory.com/47\n",
        "- https://m.blog.naver.com/idrukawa/221572225819\n",
        "- https://kr.mathworks.com/solutions/deep-learning/convolutional-neural-network.html\n",
        "- 자율주행\n",
        "- https://news.samsung.com/kr/%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89-%EC%9E%90%EB%8F%99%EC%B0%A8-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9C%BC%EB%A1%9C-%EC%8B%9C%EB%8F%99-%EA%B1%B4%EB%8B%A4"
      ]
    }
  ]
}